{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge dlib=19.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib #land mark detection & face alignment\n",
    "import matplotlib.pyplot as plt #img 띄우기\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import numpy as np #행렬 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector() #얼굴 영역 인식\n",
    "sp = dlib.shape_predictor('models/shape_predictor_5_face_landmarks.dat') #5점 랜드마크 모델로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dlib.load_rgb_image('imgs/01.jpg') #이미지 로드\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_result = img.copy()\n",
    "\n",
    "dets = detector(img, 1)#얼굴 영역 개수\n",
    "\n",
    "if len(dets) == 0:#얼굴 찾지 못하면\n",
    "    print('cannot find faces!')\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(16, 10))\n",
    "\n",
    "for det in dets: #얼굴 영역의 사각형\n",
    "    x, y, w, h = det.left(), det.top(), det.width(), det.height()\n",
    "\n",
    "    rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none') #사각형 그리기\n",
    "    ax.add_patch(rect) #그래프영역에 그해프 추가\n",
    "\n",
    "ax.imshow(img_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Landmarks 5points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(16, 10))\n",
    "\n",
    "objs = dlib.full_object_detections()\n",
    "\n",
    "for detection in dets:\n",
    "    s = sp(img, detection)\n",
    "    objs.append(s)\n",
    "    \n",
    "    for point in s.parts():\n",
    "        circle = patches.Circle((point.x, point.y), radius=3, edgecolor='r', facecolor='r')\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "ax.imshow(img_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = dlib.get_face_chips(img, objs, size=256, padding=0.3)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(faces)+1, figsize=(20, 16))\n",
    "\n",
    "axes[0].imshow(img)\n",
    "\n",
    "for i, face in enumerate(faces):\n",
    "    axes[i+1].imshow(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_faces(img):\n",
    "    dets = detector(img, 1)\n",
    "    \n",
    "    objs = dlib.full_object_detections()\n",
    "\n",
    "    for detection in dets:\n",
    "        s = sp(img, detection)\n",
    "        objs.append(s)\n",
    "        \n",
    "    faces = dlib.get_face_chips(img, objs, size=256, padding=0.35)\n",
    "    \n",
    "    return faces\n",
    "\n",
    "# test\n",
    "test_img = dlib.load_rgb_image('imgs/02.jpg')\n",
    "\n",
    "test_faces = align_faces(test_img)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(test_faces)+1, figsize=(20, 16))\n",
    "axes[0].imshow(test_img)\n",
    "\n",
    "for i, face in enumerate(test_faces):\n",
    "    axes[i+1].imshow(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BeautyGAN Pretrained\n",
    "- https://drive.google.com/drive/folders/1pgVqnF2-rnOxcUQ3SO4JwHUFTdiSe5t9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.import_meta_graph('models/model.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "X = graph.get_tensor_by_name('X:0') # source\n",
    "Y = graph.get_tensor_by_name('Y:0') # reference\n",
    "Xs = graph.get_tensor_by_name('generator/xs:0') # output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and Postprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    return img.astype(np.float32) / 127.5 - 1.\n",
    "\n",
    "def postprocess(img):\n",
    "    return ((img + 1.) * 127.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = dlib.load_rgb_image('imgs/12.jpg')\n",
    "img1_faces = align_faces(img1)\n",
    "\n",
    "img2 = dlib.load_rgb_image('imgs/makeup/XMY-014.png')\n",
    "img2_faces = align_faces(img2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 10))\n",
    "axes[0].imshow(img1_faces[0])\n",
    "axes[1].imshow(img2_faces[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_img = img1_faces[0]\n",
    "ref_img = img2_faces[0]\n",
    "\n",
    "X_img = preprocess(src_img)\n",
    "X_img = np.expand_dims(X_img, axis=0)\n",
    "\n",
    "Y_img = preprocess(ref_img)\n",
    "Y_img = np.expand_dims(Y_img, axis=0)\n",
    "\n",
    "output = sess.run(Xs, feed_dict={\n",
    "    X: X_img,\n",
    "    Y: Y_img\n",
    "})\n",
    "\n",
    "output_img = postprocess(output[0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "axes[0].set_title('Source')\n",
    "axes[0].imshow(src_img)\n",
    "axes[1].set_title('Reference')\n",
    "axes[1].imshow(ref_img)\n",
    "axes[2].set_title('Result')\n",
    "axes[2].imshow(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
